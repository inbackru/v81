#!/usr/bin/env python3
"""
Multi-City Sitemap Generator for InBack.ru
Generates comprehensive sitemap with city-based URLs for all 8 cities
"""

import os
import sys

# Add parent directory to path to import Flask app
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from datetime import datetime


def generate_sitemap():
    """Generate comprehensive sitemap with city-based URLs"""
    
    # Import Flask app and models inside function to avoid circular imports
    from app import app, db
    from models import City, Property, ResidentialComplex
    
    print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è sitemap —Å –º—É–ª—å—Ç–∏–≥–æ—Ä–æ–¥—Å–∫–∏–º–∏ URL...")
    
    base_url = "https://inback.ru"
    today = datetime.now().strftime('%Y-%m-%d')
    
    # Start XML
    sitemap_xml = '''<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
'''
    
    url_count = 0
    
    with app.app_context():
        # 1. HOMEPAGE
        print("üè† –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
        sitemap_xml += f'''  <url>
    <loc>{base_url}/</loc>
    <lastmod>{today}</lastmod>
    <changefreq>daily</changefreq>
    <priority>1.0</priority>
  </url>
'''
        url_count += 1
        
        # 2. MAIN PAGES (Global, not city-specific)
        print("üìÑ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü...")
        main_pages = [
            {'url': '/properties', 'priority': '0.9', 'changefreq': 'daily'},
            {'url': '/residential-complexes', 'priority': '0.9', 'changefreq': 'daily'},
            {'url': '/developers', 'priority': '0.8', 'changefreq': 'weekly'},
            {'url': '/map', 'priority': '0.8', 'changefreq': 'weekly'},
            {'url': '/about', 'priority': '0.8', 'changefreq': 'monthly'},
            {'url': '/how-it-works', 'priority': '0.8', 'changefreq': 'monthly'},
            {'url': '/reviews', 'priority': '0.7', 'changefreq': 'weekly'},
            {'url': '/contacts', 'priority': '0.7', 'changefreq': 'monthly'},
            {'url': '/blog', 'priority': '0.8', 'changefreq': 'daily'},
            {'url': '/news', 'priority': '0.7', 'changefreq': 'daily'},
            {'url': '/ipoteka', 'priority': '0.8', 'changefreq': 'weekly'},
            {'url': '/family-mortgage', 'priority': '0.7', 'changefreq': 'monthly'},
            {'url': '/it-mortgage', 'priority': '0.7', 'changefreq': 'monthly'},
            {'url': '/military-mortgage', 'priority': '0.7', 'changefreq': 'monthly'},
            {'url': '/developer-mortgage', 'priority': '0.7', 'changefreq': 'monthly'},
            {'url': '/maternal-capital', 'priority': '0.7', 'changefreq': 'monthly'},
            {'url': '/comparison', 'priority': '0.6', 'changefreq': 'weekly'},
            {'url': '/complex-comparison', 'priority': '0.6', 'changefreq': 'weekly'},
        ]
        
        for page in main_pages:
            sitemap_xml += f'''  <url>
    <loc>{base_url}{page['url']}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>{page['changefreq']}</changefreq>
    <priority>{page['priority']}</priority>
  </url>
'''
            url_count += 1
        
        # 3. QUERY ALL ACTIVE CITIES FROM DATABASE
        print("üåç –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        cities = City.query.filter_by(is_active=True).order_by(City.name).all()
        print(f"   –ù–∞–π–¥–µ–Ω–æ {len(cities)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤")
        
        # 4. CITY-BASED PROPERTIES PAGES (/<city_slug>/properties)
        print("üèòÔ∏è –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü —Å–≤–æ–π—Å—Ç–≤ –ø–æ –≥–æ—Ä–æ–¥–∞–º...")
        for city in cities:
            sitemap_xml += f'''  <url>
    <loc>{base_url}/{city.slug}/properties</loc>
    <lastmod>{today}</lastmod>
    <changefreq>daily</changefreq>
    <priority>0.9</priority>
  </url>
'''
            url_count += 1
        
        # 5. CITY-BASED RESIDENTIAL COMPLEXES PAGES (/<city_slug>/residential-complexes)
        print("üè¢ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü –∂–∏–ª—ã—Ö –∫–æ–º–ø–ª–µ–∫—Å–æ–≤ –ø–æ –≥–æ—Ä–æ–¥–∞–º...")
        for city in cities:
            sitemap_xml += f'''  <url>
    <loc>{base_url}/{city.slug}/residential-complexes</loc>
    <lastmod>{today}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.8</priority>
  </url>
'''
            url_count += 1
        
        # 6. INDIVIDUAL PROPERTIES (/<city_slug>/object/<id>)
        print("üè† –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏...")
        properties = Property.query.filter_by(is_active=True).all()
        print(f"   –ù–∞–π–¥–µ–Ω–æ {len(properties)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤")
        
        print("   –î–æ–±–∞–≤–ª–µ–Ω–∏–µ URL –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏...")
        for prop in properties:
            # Get city slug for the property
            city_slug = prop.city.slug if prop.city else 'krasnodar'
            sitemap_xml += f'''  <url>
    <loc>{base_url}/{city_slug}/object/{prop.id}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.7</priority>
  </url>
'''
            url_count += 1
        
        # 7. INDIVIDUAL RESIDENTIAL COMPLEXES (/<city_slug>/zk/<slug>)
        print("üèóÔ∏è –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –∂–∏–ª—ã—Ö –∫–æ–º–ø–ª–µ–∫—Å–æ–≤...")
        complexes = ResidentialComplex.query.filter_by(is_active=True).all()
        print(f"   –ù–∞–π–¥–µ–Ω–æ {len(complexes)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –∂–∏–ª—ã—Ö –∫–æ–º–ø–ª–µ–∫—Å–æ–≤")
        
        print("   –î–æ–±–∞–≤–ª–µ–Ω–∏–µ URL –∂–∏–ª—ã—Ö –∫–æ–º–ø–ª–µ–∫—Å–æ–≤...")
        for complex in complexes:
            # Get city slug for the complex
            city_slug = complex.city.slug if complex.city else 'krasnodar'
            sitemap_xml += f'''  <url>
    <loc>{base_url}/{city_slug}/zk/{complex.slug}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.7</priority>
  </url>
'''
            url_count += 1
        
        # 8. BLOG CATEGORIES
        print("üìù –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –±–ª–æ–≥–∞...")
        blog_categories = ['cashback', 'districts', 'mortgage', 'market', 'legal', 'tips']
        for category in blog_categories:
            sitemap_xml += f'''  <url>
    <loc>{base_url}/blog/category/{category}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>daily</changefreq>
    <priority>0.7</priority>
  </url>
'''
            url_count += 1
    
    # Close XML
    sitemap_xml += '</urlset>'
    
    # Save to file
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ sitemap...")
    os.makedirs('static', exist_ok=True)
    sitemap_path = 'static/sitemap.xml'
    
    with open(sitemap_path, 'w', encoding='utf-8') as f:
        f.write(sitemap_xml)
    
    # Print summary
    print("\n" + "="*60)
    print("‚úÖ SITEMAP –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù!")
    print("="*60)
    print(f"üìä –í—Å–µ–≥–æ URL: {url_count}")
    print(f"üåç –ì–æ—Ä–æ–¥–æ–≤: {len(cities)}")
    print(f"üè† –û–±—ä–µ–∫—Ç–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏: {len(properties)}")
    print(f"üè¢ –ñ–∏–ª—ã—Ö –∫–æ–º–ø–ª–µ–∫—Å–æ–≤: {len(complexes)}")
    print(f"üìÅ –§–∞–π–ª: {sitemap_path}")
    print(f"üåê URL: https://inback.ru/sitemap.xml")
    print("="*60)
    
    # Print city breakdown
    print("\nüåç –ì–û–†–û–î–ê –í SITEMAP:")
    with app.app_context():
        for city in cities:
            city_properties = Property.query.filter_by(city_id=city.id, is_active=True).count()
            city_complexes = ResidentialComplex.query.filter_by(city_id=city.id, is_active=True).count()
            print(f"   ‚Ä¢ {city.name} ({city.slug}): {city_properties} –æ–±—ä–µ–∫—Ç–æ–≤, {city_complexes} –ñ–ö")
    
    return sitemap_xml


def create_robots_txt():
    """Create robots.txt file"""
    
    print("\nü§ñ –°–æ–∑–¥–∞–Ω–∏–µ robots.txt...")
    
    robots_content = """User-agent: *
Allow: /

# –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è –±–æ—Ç–æ–≤
Disallow: /admin/
Disallow: /manager/
Disallow: /api/
Disallow: /uploads/
Disallow: /static/temp/
Disallow: /login
Disallow: /logout
Disallow: *.pdf$
Disallow: /*?print=*
Disallow: /*?*sort=*
Disallow: /*?*filter=*

# –†–∞–∑—Ä–µ—à–∞–µ–º –≤–∞–∂–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
Allow: /static/css/
Allow: /static/js/
Allow: /static/images/
Allow: /static/sitemap.xml
Allow: /sitemap.xml

# –í—Ä–µ–º—è –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
Crawl-delay: 1

# –ö–∞—Ä—Ç–∞ —Å–∞–π—Ç–∞
Sitemap: https://inback.ru/sitemap.xml

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤–∏–∫–æ–≤
User-agent: Googlebot
Crawl-delay: 1
Allow: /api/properties
Allow: /api/residential-complexes

User-agent: Yandex
Crawl-delay: 1
Allow: /api/properties
Allow: /api/residential-complexes

User-agent: Bingbot  
Crawl-delay: 2

# –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã—Ö –±–æ—Ç–æ–≤
User-agent: SemrushBot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: MJ12bot
Disallow: /
"""
    
    os.makedirs('static', exist_ok=True)
    with open('static/robots.txt', 'w', encoding='utf-8') as f:
        f.write(robots_content)
    
    print("‚úÖ robots.txt –æ–±–Ω–æ–≤–ª–µ–Ω")


if __name__ == '__main__':
    print("="*60)
    print("üöÄ –ì–ï–ù–ï–†–ê–¢–û–† SITEMAP –î–õ–Ø INBACK.RU")
    print("   –ú—É–ª—å—Ç–∏–≥–æ—Ä–æ–¥—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ (8 –≥–æ—Ä–æ–¥–æ–≤)")
    print("="*60)
    print()
    
    try:
        generate_sitemap()
        create_robots_txt()
        print("\n‚úÖ –í–°–ï –ì–û–¢–û–í–û! Sitemap –∏ robots.txt —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã")
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
