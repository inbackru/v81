#!/usr/bin/env python3
"""
ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾ Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ð¿Ð°Ñ€ÑÐµÑ€ Ð·Ð°ÑÑ‚Ñ€Ð¾Ð¹Ñ‰Ð¸ÐºÐ¾Ð²
Ð Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾, Ð½Ð¾ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
"""

import time
import re
import logging
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import json

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

def create_minimal_driver():
    """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð¾Ð±Ð»ÐµÐ³Ñ‡ÐµÐ½Ð½Ñ‹Ð¹ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€"""
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--disable-extensions')
    options.add_argument('--disable-plugins')
    options.add_argument('--disable-images')  # ÐÐµ Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¸
    # ÐÐ• Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ JS - Ð½ÑƒÐ¶ÐµÐ½ Ð´Ð»Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
    # options.add_argument('--disable-javascript')
    options.add_argument('--memory-pressure-off')
    options.add_argument('--max_old_space_size=512')  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ð°Ð¼ÑÑ‚ÑŒ
    options.add_argument('--aggressive-cache-discard')
    
    # ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð½ÐµÐ½ÑƒÐ¶Ð½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸
    prefs = {
        "profile.managed_default_content_settings.images": 2,
        "profile.default_content_setting_values.media_stream": 2,
        "profile.managed_default_content_settings.media_stream": 2
    }
    options.add_experimental_option("prefs", prefs)
    
    return webdriver.Chrome(options=options)

def extract_developers_from_etagi_simple(url):
    """ÐŸÑ€Ð¾ÑÑ‚Ð¾Ðµ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ etagi.com Ð±ÐµÐ· Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸"""
    logger.info(f"ðŸŒ ÐŸÑ€Ð¾ÑÑ‚Ð¾Ðµ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ {url}")
    
    driver = None
    try:
        driver = create_minimal_driver()
        driver.set_page_load_timeout(30)  # Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ 30 ÑÐµÐº
        
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñƒ
        driver.get(url)
        logger.info("âœ… Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°")
        
        # Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð’Ð¡Ð•Ð¥ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐµÐº
        time.sleep(8)
        
        # ÐœÐµÐ´Ð»ÐµÐ½Ð½Ð¾ ÑÐºÑ€Ð¾Ð»Ð»Ð¸Ð¼ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ€Ð°Ð· Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð²ÑÐµÑ… ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐµÐº
        logger.info("Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð²ÑÐµ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð¿Ð¾ÑÑ‚ÐµÐ¿ÐµÐ½Ð½Ñ‹Ð¼ ÑÐºÑ€Ð¾Ð»Ð»Ð¾Ð¼...")
        for i in range(10):
            driver.execute_script(f"window.scrollTo(0, {(i+1) * 800});")
            time.sleep(2)
        
        # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐºÑ€Ð¾Ð»Ð» Ð´Ð¾ ÐºÐ¾Ð½Ñ†Ð°
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(5)
        
        # ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¸ Ð½Ð°Ð¶Ð°Ñ‚ÑŒ ÐºÐ½Ð¾Ð¿ÐºÐ¸ "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÐµÑ‰Ðµ"
        for attempt in range(3):
            try:
                buttons = driver.find_elements(By.XPATH, "//button[contains(text(), 'ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ') or contains(text(), 'ÐµÑ‰Ðµ') or contains(text(), 'Ð•Ñ‰Ñ‘')]")
                if buttons:
                    for btn in buttons:
                        try:
                            driver.execute_script("arguments[0].click();", btn)
                            time.sleep(4)
                            logger.info(f"ÐÐ°Ð¶Ð°Ñ‚Ð° ÐºÐ½Ð¾Ð¿ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ (Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ° {attempt+1})")
                        except:
                            pass
                else:
                    break
            except:
                break
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ HTML Ð¿Ð¾ÑÐ»Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
        html = driver.page_source
        logger.info(f"âœ… ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ HTML Ñ€Ð°Ð·Ð¼ÐµÑ€Ð¾Ð¼ {len(html)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²")
        
        # ÐžÑÐ²Ð¾Ð±Ð¾Ð¶Ð´Ð°ÐµÐ¼ Ð¿Ð°Ð¼ÑÑ‚ÑŒ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð°
        driver.quit()
        driver = None
        
        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ HTML
        soup = BeautifulSoup(html, 'html.parser')
        developers = []
        
        # Ð˜Ñ‰ÐµÐ¼ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ
        all_text = soup.get_text()
        
        # ÐŸÑ€Ð¾ÑÑ‚Ñ‹Ðµ, Ð½Ð¾ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð´Ð»Ñ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ñ… Ð·Ð°ÑÑ‚Ñ€Ð¾Ð¹Ñ‰Ð¸ÐºÐ¾Ð²
        patterns = [
            r'(Ð“Ðš\s+Ð¡Ð¼ÐµÐ½Ð°)',
            r'(Ð¤Ð›ÐÐ“ÐœÐÐ)',
            r'(Ð”Ð°Ñ€ÑÑ‚Ñ€Ð¾Ð¹)',
            r'(Ð‘Ð­Ð›\s+Ð”Ð•Ð’Ð•Ð›ÐžÐŸÐœÐ•ÐÐ¢)',
            r'(Ð¡Ð¡Ðš)',
            r'(Ð­Ñ‚Ð°Ð¶Ð¸)',
            r'(Ð Ð¾Ð¼ÐµÐºÑ\s+Ð”ÐµÐ²ÐµÐ»Ð¾Ð¿Ð¼ÐµÐ½Ñ‚)',
            r'(ÐÐ¾Ð²Ð¾ÑÑ‚Ñ€Ð¾Ð¹)',
            r'(ÐÐ»ÑŒÑ„Ð°Ð¡Ñ‚Ñ€Ð¾Ð¹)',
            r'(Ð®Ð Ð¡Ðš)',
            r'(Ð˜ÐÐÐ§Ð•)',
            r'(Ð“Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ)',
            r'(Ð¡Ð°Ñ€Ð¼Ð°Ñ‚-Ð¡Ñ‚Ñ€Ð¾Ð¹)',
            r'(ÐšÐžÐÐ¢Ð˜ÐÐ•ÐÐ¢\s+Ð“Ð Ð£ÐŸÐŸ)',
            r'(Ð‘ÐÐ£Ð˜ÐÐ’Ð•Ð¡Ð¢)',
            r'(Ð¡Ðš\s+Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ÐµÐ»ÑŒ)',
            r'(Ð¡Ð—\s+Ð¢Ð’ÐžÐ•\s+ÐœÐ•Ð¡Ð¢Ðž)',
            r'(ÐšÑ€Ð°ÑÐ½Ð¾Ð´Ð°Ñ€\s+Ð¡Ñ‚Ñ€Ð¾Ð¹)',
            r'(ÐžÐ»Ð¸Ð¼Ð¿\s+Ð¡Ñ‚Ñ€Ð¾Ð¹)',
            r'(ÐÐ“Ðš)',
            r'(ÐÐ±ÑÐ¾Ð»ÑŽÑ‚\s+Ð“Ñ€ÑƒÐ¿Ð¿)',
            r'(Ð”ÐžÐ“ÐœÐ)',
            r'(ÐŸÑ€ÐµÐ¼ÑŒÐµÑ€)',
            r'(Ð¡Ñ‚Ñ€Ð¾Ð¹Ð³Ñ€Ð°Ð´)',
            r'(Ð’ÐµÐºÑ‚Ð¾Ñ€)',
            r'(Ð‘Ð°ÑƒÐ²ÐµÑÑ‚)',
            r'(Ð˜Ð½Ð³Ñ€Ð°Ð´)',
            r'(Ð¡Ð¸Ð¼Ð¿Ð»ÐµÐºÑ)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, all_text, re.IGNORECASE)
            for match in matches:
                name = match.strip()
                if name and not any(d['name'] == name for d in developers):
                    developers.append({
                        'name': name,
                        'description': f'Ð—Ð°ÑÑ‚Ñ€Ð¾Ð¹Ñ‰Ð¸Ðº {name} - Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ etagi.com',
                        'source': 'etagi.com',
                        'url': url,
                        'specialization': 'Ð–Ð¸Ð»Ð¸Ñ‰Ð½Ð¾Ðµ ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð¾'
                    })
                    logger.info(f"  âœ… {name}")
        
        # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¸Ñ‰ÐµÐ¼ Ð² ÑÑÑ‹Ð»ÐºÐ°Ñ… Ð¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°Ñ…
        links = soup.find_all('a', href=re.compile(r'/zastr/|builder'))
        for link in links:
            text = link.get_text(strip=True)
            if text and len(text) > 2 and len(text) < 50:
                # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð¾Ñ‚ Ð»Ð¸ÑˆÐ½ÐµÐ³Ð¾
                text = re.sub(r'ÐžÐ¿Ñ‹Ñ‚ Ð² ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ðµ.*', '', text)
                text = re.sub(r'ÐšÐ²Ð°Ñ€Ñ‚Ð¸Ñ€ Ð² Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ðµ.*', '', text)
                text = re.sub(r'Ð‘Ð¾Ð»ÐµÐµ \d+.*', '', text)
                text = text.strip()
                
                if text and not any(d['name'] == text for d in developers):
                    excluded = ['Ð¶Ð¸Ð»Ñ‹Ðµ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÑ‹', 'Ð½Ð¾Ð²Ð¾ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸', 'ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€Ñ‹', 'Ð´Ð¾Ð¼Ð°', 'ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð¾']
                    if text.lower() not in excluded:
                        developers.append({
                            'name': text,
                            'description': f'Ð—Ð°ÑÑ‚Ñ€Ð¾Ð¹Ñ‰Ð¸Ðº {text} - Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ etagi.com',
                            'source': 'etagi.com',
                            'url': url,
                            'specialization': 'Ð–Ð¸Ð»Ð¸Ñ‰Ð½Ð¾Ðµ ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð¾'
                        })
                        logger.info(f"  âœ… {text}")
        
        logger.info(f"ðŸ¢ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(developers)} Ð·Ð°ÑÑ‚Ñ€Ð¾Ð¹Ñ‰Ð¸ÐºÐ¾Ð²")
        return developers
        
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ðµ {url}: {e}")
        return []
        
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

def run_memory_safe_scraping():
    """Ð—Ð°Ð¿ÑƒÑÐº Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ð³Ð¾ Ð¿Ð¾ Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°"""
    logger.info("ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¿Ð°Ñ€ÑÐµÑ€Ð°...")
    
    urls = [
        "https://krasnodar.etagi.com/zastr/builders/"
    ]
    
    all_developers = []
    
    for url in urls:
        try:
            developers = extract_developers_from_etagi_simple(url)
            all_developers.extend(developers)
            
            # ÐŸÐ°ÑƒÐ·Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸ Ð´Ð»Ñ ÑÐ½Ð¸Ð¶ÐµÐ½Ð¸Ñ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
            time.sleep(2)
            
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ {url}: {e}")
            continue
    
    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹
    unique_developers = []
    seen_names = set()
    
    for dev in all_developers:
        if dev['name'] not in seen_names:
            unique_developers.append(dev)
            seen_names.add(dev['name'])
    
    logger.info(f"ðŸŽ¯ Ð˜Ñ‚Ð¾Ð³Ð¾ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {len(unique_developers)} ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð·Ð°ÑÑ‚Ñ€Ð¾Ð¹Ñ‰Ð¸ÐºÐ¾Ð²")
    
    return {
        'success': True,
        'developers': unique_developers,
        'total_processed': len(unique_developers),
        'created': len(unique_developers),
        'updated': 0,
        'errors': 0
    }

if __name__ == "__main__":
    result = run_memory_safe_scraping()
    
    print(f"âœ… Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: success={result['success']}")
    print(f"ðŸ¢ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð·Ð°ÑÑ‚Ñ€Ð¾Ð¹Ñ‰Ð¸ÐºÐ¾Ð²: {result['total_processed']}")
    
    print("\nÐŸÐµÑ€Ð²Ñ‹Ðµ 15 Ð·Ð°ÑÑ‚Ñ€Ð¾Ð¹Ñ‰Ð¸ÐºÐ¾Ð²:")
    for i, dev in enumerate(result['developers'][:15], 1):
        print(f"  {i}. {dev['name']} (Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº: {dev['source']})")